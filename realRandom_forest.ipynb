{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26720, 12) (6681, 12) (26720,) (6681,)\n",
      "      danceability    energy       key  loudness      mode  acousticness  \\\n",
      "4293     -0.064347  1.007892 -0.339478  1.524700  0.651748      0.133834   \n",
      "1764     -0.347443  1.646478 -0.904754  1.164583  0.651748     -0.775594   \n",
      "5740      0.372093  0.483490  1.638992  1.050279  0.651748     -1.025205   \n",
      "5845     -1.403157 -0.616063  1.073715  0.177796  0.651748     -0.108150   \n",
      "8182     -0.813373 -1.385750  1.073715 -0.540789  0.651748      1.582670   \n",
      "...            ...       ...       ...       ...       ...           ...   \n",
      "3864     -1.379565 -0.937471 -0.339478 -0.849293 -1.534336     -0.729955   \n",
      "7255      0.147975  0.796439 -1.187393  1.124518  0.651748     -0.334817   \n",
      "5487      1.392419 -0.704873  1.638992 -1.402667  0.651748     -0.031573   \n",
      "2093      1.244973  1.287009 -1.187393  0.045580  0.651748     -0.699324   \n",
      "5566      0.006427  1.274322  1.356353  1.005029  0.651748     -0.891379   \n",
      "\n",
      "      liveness   valence     tempo  duration_ms  chorus_hit  sections  \n",
      "4293 -0.553249  1.250482 -1.348167    -0.548263    0.598848 -1.377467  \n",
      "1764  1.011586  0.044590 -0.226392    -1.712791   -0.524644 -0.672870  \n",
      "5740  1.374170 -0.424584 -0.698897    -0.015587   -1.254194  0.031727  \n",
      "5845  0.916169 -1.176812 -1.986262    -0.886275   -0.883070 -1.377467  \n",
      "8182  2.003920 -0.754168 -0.803951    -1.520246    0.081802 -2.082064  \n",
      "...        ...       ...       ...          ...         ...       ...  \n",
      "3864 -0.838545 -1.673128  0.131078    -1.177415    2.167885 -1.729765  \n",
      "7255  0.515419  1.413336  0.880808    -1.049324   -0.170121 -0.320571  \n",
      "5487 -0.922512  0.723147 -0.492516    -0.053057   -0.487023  1.440921  \n",
      "2093  0.897086  1.564557 -0.405399     0.408023    1.161394 -0.672870  \n",
      "5566 -0.742174  0.025203  1.290137     1.518583   -0.414189  0.384025  \n",
      "\n",
      "[20040 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_00 = pd.read_csv(\"dataset-of-00s.csv\")\n",
    "df_10 = pd.read_csv(\"dataset-of-10s.csv\")\n",
    "df_60 = pd.read_csv(\"dataset-of-60s.csv\")\n",
    "df_70 = pd.read_csv(\"dataset-of-70s.csv\")\n",
    "df_80 = pd.read_csv(\"dataset-of-80s.csv\")\n",
    "df_90 = pd.read_csv(\"dataset-of-90s.csv\")\n",
    "\n",
    "df = pd.concat([df_00, df_10, df_60, df_70, df_80, df_90])\n",
    "df = df.drop(axis=1, labels='time_signature')\n",
    "#Scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "df_X = df.iloc[:,3:17]\n",
    "\n",
    "\n",
    "df_scaled = scale.fit_transform(df_X)\n",
    "df_scaled = pd.DataFrame(df_scaled)\n",
    "df_scaled.columns = df_X.columns\n",
    "df_scaled\n",
    "\n",
    "\n",
    "df_clean= df_scaled\n",
    "for col in df_clean.columns:\n",
    "  q1=df_clean[col].quantile(0.25)\n",
    "  q3=df_clean[col].quantile(0.75)\n",
    "  inq=q3-q1\n",
    "  filter=(df_clean[col] >= q1-1.5*inq) & (df_clean[col] <= q3+1.5*inq)\n",
    "  df_clean[col] = df_clean[col].loc[filter]\n",
    "#Removing outliers\n",
    "\n",
    "df_clean = df_clean.drop(axis=1, labels=['speechiness', 'instrumentalness'])\n",
    "\n",
    "df_remove = df_clean.dropna()\n",
    "#Removing missing values\n",
    "df_remove.shape\n",
    "#The number of songs remaining is 33401\n",
    "df_merge = df.iloc[df_remove.index]\n",
    "df_merge = df_merge.drop(axis=1, labels=['speechiness', 'instrumentalness'])\n",
    "df_merge.columns\n",
    "#Removed the predictors that were not used from the original dataset\n",
    "\n",
    "#observations in each class\n",
    "df_merge.groupby('target')[['danceability', 'energy', 'key', 'loudness',\n",
    "       'mode', 'acousticness', 'liveness', 'valence', 'tempo', 'duration_ms',\n",
    "       'chorus_hit', 'sections']].count()\n",
    "\n",
    "\n",
    "df_merge.iloc[:,3:15]\n",
    "#creating final scaled data with all the variables\n",
    "scale = StandardScaler()\n",
    "scale_X = scale.fit_transform(df_merge.iloc[:,3:15])\n",
    "df_merge.iloc[:,3:15] = scale_X\n",
    "\n",
    "X = df_merge.iloc[:,3:15]\n",
    "X.shape\n",
    "\n",
    "y = df_merge['target']\n",
    "y.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "X_train_final, X_valid, y_train_final, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "print(X_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sklearn's RandomForest: 0.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train, X_val, y_train, y_val are already defined and are numpy arrays.\n",
    "\n",
    "# Step 2: Create a RandomForestClassifier object\n",
    "# Note: The parameters n_estimators, max_depth, and max_features should be similar to the ones you used in your from-scratch implementation for a fair comparison.\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10, max_depth=5, max_features='sqrt')\n",
    "\n",
    "# Step 3: Fit the model to your training data\n",
    "rf_classifier.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Step 4: Predict the labels for your validation data\n",
    "predictions_sklearn = rf_classifier.predict(X_valid)\n",
    "\n",
    "# Step 5: Calculate the accuracy of the predictions\n",
    "accuracy_sklearn = accuracy_score(y_valid, predictions_sklearn)\n",
    "print(f\"Accuracy of sklearn's RandomForest: {accuracy_sklearn:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Helper function to compute Gini impurity\n",
    "def gini_impurity(labels):\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    impurity = 1.0 - np.sum((counts / len(labels))**2)\n",
    "    return impurity\n",
    "\n",
    "# Function to perform a split on a node\n",
    "def split_node(X, y, index, value):\n",
    "    left_mask = X[:, index] <= value\n",
    "    right_mask = X[:, index] > value\n",
    "    return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "# Function to find unique values in a feature column\n",
    "def unique_values(data):\n",
    "    return np.unique(data)\n",
    "\n",
    "# Best split based on Gini impurity\n",
    "def get_best_split(X, y, n_features):\n",
    "    best_feature, best_value, best_score, best_groups = None, None, float(\"inf\"), None\n",
    "    features = np.random.choice(X.shape[1], n_features, replace=False)\n",
    "    for feature in features:\n",
    "        values = unique_values(X[:, feature])\n",
    "        for value in values:\n",
    "            left_X, right_X, left_y, right_y = split_node(X, y, feature, value)\n",
    "            if len(left_y) == 0 or len(right_y) == 0:\n",
    "                continue\n",
    "            gini = (gini_impurity(left_y) * len(left_y) + gini_impurity(right_y) * len(right_y)) / len(y)\n",
    "            if gini < best_score:\n",
    "                best_feature, best_value, best_score, best_groups = feature, value, gini, (left_X, right_X, left_y, right_y)\n",
    "    return {'index': best_feature, 'value': best_value, 'groups': best_groups}\n",
    "\n",
    "# Decision tree class\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth, n_features):\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.tree = None\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(np.unique(y)) == 1 or depth >= self.max_depth:\n",
    "            return np.argmax(np.bincount(y))\n",
    "        node = get_best_split(X, y, self.n_features)\n",
    "        if not node['groups']:\n",
    "            return np.argmax(np.bincount(y))\n",
    "        left_X, right_X, left_y, right_y = node['groups']\n",
    "        return {'feature_index': node['index'], 'threshold': node['value'],\n",
    "                'left': self._build_tree(left_X, left_y, depth + 1),\n",
    "                'right': self._build_tree(right_X, right_y, depth + 1)}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, 0)\n",
    "\n",
    "    def _predict_one(self, observation, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        if observation[tree['feature_index']] <= tree['threshold']:\n",
    "            return self._predict_one(observation, tree['left'])\n",
    "        else:\n",
    "            return self._predict_one(observation, tree['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_one(x, self.tree) for x in X]\n",
    "\n",
    "# Random Forest class\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees, max_depth, n_features):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.forest = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.forest = []\n",
    "        for _ in range(self.n_trees):\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            tree = DecisionTree(self.max_depth, self.n_features)\n",
    "            tree.fit(X[indices], y[indices])\n",
    "            self.forest.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = [tree.predict(X) for tree in self.forest]\n",
    "        predictions = np.array([np.argmax(np.bincount(preds)) for preds in np.array(tree_preds).T])\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = np.sum(actual == predicted)\n",
    "    return correct / len(actual) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 71.19261477045909\n",
      "Validation Accuracy: 69.8502994011976\n",
      "Test Accuracy: 69.79494087711421\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays\n",
    "X_train_np = X_train_final.to_numpy()\n",
    "y_train_np = y_train_final.to_numpy()\n",
    "X_valid_np = X_valid.to_numpy()\n",
    "y_valid_np = y_valid.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "# Define hyperparameters\n",
    "n_trees = 10\n",
    "max_depth = 5\n",
    "n_features = int(np.sqrt(X_train_np.shape[1]))\n",
    "\n",
    "# Initialize and train the random forest model\n",
    "rf_model = RandomForest(n_trees=n_trees, max_depth=max_depth, n_features=n_features)\n",
    "rf_model.fit(X_train_np, y_train_np)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = rf_model.predict(X_train_np)\n",
    "y_pred_valid = rf_model.predict(X_valid_np)\n",
    "y_pred_test = rf_model.predict(X_test_np)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_metric(y_train_np, y_pred_train)\n",
    "valid_accuracy = accuracy_metric(y_valid_np, y_pred_valid)\n",
    "test_accuracy = accuracy_metric(y_test_np, y_pred_test)\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Validation Accuracy:\", valid_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
